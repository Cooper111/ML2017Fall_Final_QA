{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec # load wordEmbedding model\n",
    "import numpy as np\n",
    "import math, csv\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.core import *\n",
    "from keras.models import *\n",
    "from keras.utils import plot_model\n",
    "from keras.activations import softmax\n",
    "\n",
    "PARAGRAPH_LENGTH = 650\n",
    "QUESTION_LENGTH = 60\n",
    "W2V_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def QA_model_AF(lstm_units=64):\n",
    "    # Contextual Embedding Layer\n",
    "    paragraph = Input(shape=(PARAGRAPH_LENGTH,W2V_LENGTH),name='INPUT_paragraph')\n",
    "    question = Input(shape=(QUESTION_LENGTH,W2V_LENGTH),name='INPUT_question')\n",
    "    \n",
    "    q = Bidirectional(LSTM(lstm_units, return_sequences=True))(question)\n",
    "    p = Bidirectional(LSTM(lstm_units, return_sequences=True))(paragraph)\n",
    "    \n",
    "    p_c = Flatten()(p)\n",
    "    p_c = RepeatVector(QUESTION_LENGTH)(p_c)\n",
    "    p_c = Reshape((QUESTION_LENGTH,PARAGRAPH_LENGTH,lstm_units*2))(p_c)\n",
    "    p_c = Permute((2,1,3))(p_c)\n",
    "    \n",
    "    q_c = Flatten()(q)\n",
    "    q_c = RepeatVector(PARAGRAPH_LENGTH)(q_c)\n",
    "    q_c = Reshape((PARAGRAPH_LENGTH,QUESTION_LENGTH,lstm_units*2))(q_c)\n",
    "    \n",
    "    # Making Similarity Matrix\n",
    "    m = Multiply()([p_c,q_c])\n",
    "    s0 = Concatenate(axis=3)([p_c,q_c,m])\n",
    "    s1 = Dense(units=1)(s0)\n",
    "    s = Reshape((PARAGRAPH_LENGTH,QUESTION_LENGTH))(s1)\n",
    "    \n",
    "    # Attetion Flow\n",
    "    c2q = Lambda(lambda x: softmax(x,axis=2))(s)\n",
    "    c2q_c = Flatten()(c2q)\n",
    "    c2q_c = RepeatVector(lstm_units*2)(c2q_c)\n",
    "    c2q_c = Reshape((lstm_units*2,PARAGRAPH_LENGTH,QUESTION_LENGTH))(c2q_c)\n",
    "    c2q_c = Permute((2,3,1))(c2q_c)\n",
    "    m_q = Multiply()([c2q_c,q_c])\n",
    "    q_att = Lambda(lambda x: K.sum(x,axis=2))(m_q)\n",
    "    \n",
    "    q2c = Lambda(lambda x: K.max(x,axis=2))(s)\n",
    "    q2c = Lambda(lambda x: K.softmax(x))(q2c)\n",
    "    q2c_c = RepeatVector(lstm_units*2)(q2c)\n",
    "    q2c_c = Permute((2,1))(q2c_c)\n",
    "    m_p = Multiply()([q2c_c,p])\n",
    "    \n",
    "    p_att = Lambda(lambda x: K.sum(x,axis=1))(m_p)\n",
    "    p_att = RepeatVector(PARAGRAPH_LENGTH)(p_att)\n",
    "    \n",
    "    g_0 = Multiply()([p,q_att])\n",
    "    g_1 = Multiply()([p,p_att])\n",
    "    G = Concatenate(axis=2)([p,q_att,g_0,g_1])\n",
    "    \n",
    "    # Modeling Layer\n",
    "    M_0 = Bidirectional(LSTM(lstm_units, return_sequences=True))(G)\n",
    "    M_1 = Bidirectional(LSTM(lstm_units, return_sequences=True))(M_0)\n",
    "    M_2 = Bidirectional(LSTM(lstm_units, return_sequences=True))(M_1)\n",
    "    \n",
    "    # Output Layer\n",
    "    concat_start = Concatenate(axis=2)([G,M_0]) # cut here\n",
    "    concat_end = Concatenate(axis=2)([G,M_1]) # cut here\n",
    "    \n",
    "    p_start = Dense(1)(concat_start)\n",
    "    p_end = Dense(1)(concat_end)\n",
    "    p_start = Flatten()(p_start)\n",
    "    p_end = Flatten()(p_end)\n",
    "    \n",
    "    start = Activation('softmax')(p_start)\n",
    "    end = Activation('softmax')(p_end)\n",
    "    \n",
    "    model = Model(input=[paragraph,question], output=[start,end])\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
